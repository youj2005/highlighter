{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOScQAWaJQgZ"
      },
      "source": [
        "Highlighter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XoZcqH21Jg_q",
        "outputId": "e151161b-ec0d-4dca-d161-f54a33081057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (1.5.0)\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (2.3.1)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (2.2.2)\n",
            "Requirement already satisfied: transformers in ./.venv/lib/python3.10/site-packages (4.41.2)\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch) (2024.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.venv/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.venv/lib/python3.10/site-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in ./.venv/lib/python3.10/site-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in ./.venv/lib/python3.10/site-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.venv/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn torch pandas transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ekWOSfwJQga",
        "outputId": "4949e33d-80ea-4a88-d1af-1de9ca68c282"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jadenyou/highlighter/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from highlight import HighlightHead\n",
        "from helper import HighlightHelper\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "model_name = 'google/electra-base-generator'\n",
        "\n",
        "helper = HighlightHelper(model_name=model_name)\n",
        "model = HighlightHead(outdim=4, hidden_size=helper.config.hidden_size, model_name=model_name)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "df = pd.read_pickle(\"highlights.pkl\")\n",
        "sentences_df = pd.read_pickle(\"sentences.pkl\")\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:, [0, 1]], df.iloc[:, 2], test_size=0.20, random_state=111)\n",
        "x_traiin, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=222)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "train_df = pd.concat([x_train, y_train], axis=1)\n",
        "test_df = pd.concat([x_test, y_test], axis=1)\n",
        "valid_df = pd.concat([x_val, y_val], axis=1)\n",
        "\n",
        "df_0 = train_df[train_df.iloc[:, 2] == 0]\n",
        "df_1 = train_df[train_df.iloc[:, 2] == 1]\n",
        "df_2 = train_df[train_df.iloc[:, 2] == 2]\n",
        "df_3 = train_df[train_df.iloc[:, 2] == 3]\n",
        "\n",
        "sample_num = len(train_df)//4\n",
        "df_0 = resample(df_0, replace=True, n_samples=sample_num, random_state=333)\n",
        "df_1 = resample(df_1, replace=True, n_samples=sample_num, random_state=444)\n",
        "df_2 = resample(df_2, replace=True, n_samples=sample_num, random_state=555)\n",
        "df_3 = resample(df_3, replace=True, n_samples=sample_num, random_state=666)\n",
        "\n",
        "train_df = pd.concat([df_0, df_1, df_2, df_3], axis=0)\n",
        "train_df = train_df.sample(frac=1, random_state=777).reset_index(drop=True)\n",
        "\n",
        "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "\n",
        "head_parameters = [param for name, param in list(model.named_parameters()) if \"model\" not in name and \"conv\" not in name]\n",
        "encoder_wd_parameters = [param for name, param in list(model.named_parameters()) if \"model\" in name and not any(nd in name for nd in no_decay)]\n",
        "encoder_nowd_parameters = [param for name, param in list(model.named_parameters()) if \"model\" in name and any(nd in name for nd in no_decay)]\n",
        "\n",
        "parameters = [\n",
        "    {'params': head_parameters, 'weight_decay': 0.0, 'lr': 3e-5},\n",
        "    {'params': encoder_wd_parameters, 'weight_decay': 5e-2, 'lr': 2e-5},\n",
        "    {'params': encoder_nowd_parameters, 'weight_decay': 0.0, 'lr': 2e-5},\n",
        "]\n",
        "\n",
        "optimizer = torch.optim.AdamW(parameters)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, \n",
        "    num_warmup_steps=0, \n",
        "    num_training_steps=epochs)\n",
        "\n",
        "for param in model.model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_boQHGiYJQgb",
        "outputId": "5a1c7e54-62d1-4a1b-da45-6de44209b68a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3484/3484 [01:04<00:00, 53.66it/s]\n",
            "100%|██████████| 872/872 [00:06<00:00, 133.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy:  0.3187702265372168\n",
            "Loss:  1.363064759104041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3484/3484 [00:29<00:00, 119.56it/s]\n",
            "100%|██████████| 872/872 [00:06<00:00, 138.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy:  0.3454692556634304\n",
            "Loss:  1.299812487000439\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3484/3484 [00:28<00:00, 120.18it/s]\n",
            "100%|██████████| 872/872 [00:06<00:00, 139.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy:  0.36326860841423947\n",
            "Loss:  1.2523035627162142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3484/3484 [01:25<00:00, 40.94it/s]\n",
            "100%|██████████| 872/872 [00:06<00:00, 136.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy:  0.6868932038834952\n",
            "Loss:  0.6856887516114929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3484/3484 [01:35<00:00, 36.65it/s]\n",
            "100%|██████████| 872/872 [00:06<00:00, 138.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy:  0.7305825242718447\n",
            "Loss:  0.368165525111095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3484/3484 [01:25<00:00, 40.80it/s]\n",
            "100%|██████████| 872/872 [00:06<00:00, 137.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy:  0.7330097087378641\n",
            "Loss:  0.29093699819107893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3484/3484 [01:25<00:00, 40.70it/s]\n",
            "100%|██████████| 872/872 [00:06<00:00, 136.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy:  0.7394822006472492\n",
            "Loss:  0.25181320002642016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3484/3484 [01:25<00:00, 40.91it/s]\n",
            "100%|██████████| 872/872 [00:06<00:00, 138.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy:  0.7370550161812298\n",
            "Loss:  0.22836894533411417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3484/3484 [01:25<00:00, 40.97it/s]\n",
            "100%|██████████| 872/872 [00:06<00:00, 134.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy:  0.7273462783171522\n",
            "Loss:  0.21083722729108914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3484/3484 [01:41<00:00, 34.36it/s]\n",
            "100%|██████████| 872/872 [00:06<00:00, 137.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy:  0.732200647249191\n",
            "Loss:  0.19176960226424236\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "total_loss = 0\n",
        "total_runs = 0\n",
        "loss_at_each = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    #training\n",
        "    model.train()\n",
        "    for index, item in tqdm(train_df.iterrows(), total=len(train_df)):\n",
        "        optimizer.zero_grad()\n",
        "        sentence = sentences_df.iloc[item.iloc[0][0]][0]\n",
        "        index = item.iloc[0][1]\n",
        "        tag = item.iloc[2]\n",
        "        texts, highlights, mask = helper.split_mask(\n",
        "            text=sentence,\n",
        "            index=index,\n",
        "            highlight=tag,\n",
        "            device=device\n",
        "        )\n",
        "        guess, loss = model(texts, highlights, mask)\n",
        "        # print(torch.exp(guess))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        total_runs += 1\n",
        "        loss_at_each.append(loss.item())\n",
        "    \n",
        "    scheduler.step()\n",
        "    \n",
        "    #unfreeze parameters\n",
        "    if epoch == 2:\n",
        "        for param in model.model.parameters():\n",
        "            param.requires_grad = True\n",
        "            \n",
        "    # evaluation\n",
        "    model.eval()\n",
        "    total_samples = 0\n",
        "    total_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for index, item in tqdm(valid_df.iterrows(), total=len(valid_df)):\n",
        "            sentence = sentences_df.iloc[item.iloc[0][0]][0]\n",
        "            index = item.iloc[0][1]\n",
        "            tag = item.iloc[2]\n",
        "            texts, highlights, mask = helper.split_mask(\n",
        "                text=sentence,\n",
        "                index=index,\n",
        "                highlight=tag,\n",
        "                device=device\n",
        "            )\n",
        "            guess, loss = model(texts, highlights, mask)\n",
        "            guess = torch.exp(guess).argmax(dim=1).squeeze()\n",
        "            for j in range(len(mask)):\n",
        "                if (mask[j] == 1):\n",
        "                    total_samples += 1\n",
        "                    if guess[j] == tag:\n",
        "                        total_correct += 1\n",
        "                        \n",
        "    print(\"Validation Accuracy: \", total_correct/total_samples)\n",
        "    \n",
        "    print(\"Loss: \", total_loss/total_runs)\n",
        "    total_loss = 0\n",
        "    total_runs = 0\n",
        "\n",
        "model.save(\"model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fNzzRNlJQgc",
        "outputId": "077f0fc6-7ec3-4083-ea4e-8c7532e1c232"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 872/872 [00:06<00:00, 138.91it/s]\n"
          ]
        }
      ],
      "source": [
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "model.load_state_dict(torch.load(\"model.pt\"))\n",
        "model.eval()\n",
        "\n",
        "correct_each = [0, 0, 0, 0]\n",
        "total_each = [0, 0, 0, 0]\n",
        "\n",
        "for index, item in tqdm(test_df.iterrows(), total=len(test_df)):\n",
        "    sentence = sentences_df.iloc[item.iloc[0][0]][0]\n",
        "    index = item.iloc[0][1]\n",
        "    tag = item.iloc[2]\n",
        "    texts, highlights, mask = helper.split_mask(\n",
        "        text=sentence,\n",
        "        index=index,\n",
        "        highlight=tag,\n",
        "        device=device\n",
        "    )\n",
        "    guess, loss = model(texts, highlights, mask)\n",
        "    guess = torch.exp(guess).argmax(dim=1)\n",
        "    mask = mask.squeeze()\n",
        "    for j in range(len(mask)):\n",
        "        if (mask[j] == 1):\n",
        "          total_samples += 1\n",
        "          total_each[tag] += 1\n",
        "          if guess[j] == tag:\n",
        "            total_correct += 1\n",
        "            correct_each[tag] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SejvlB83JQgc",
        "outputId": "6fdec277-ee55-4504-e1b7-bdcac6f2988c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total accuracy (micro-average):  0.7028181041844578\n",
            "Accuracy by tag:  [0.669047619047619, 0.9090909090909091, 0.5766871165644172, 0.75]\n",
            "Average accuracy (macro-average):  0.7262064111757363\n"
          ]
        }
      ],
      "source": [
        "print(\"Total accuracy (micro-average): \", total_correct/total_samples)\n",
        "accuracy_by_tag = [correct_each[i]/total_each[i] for i in range(len(correct_each))]\n",
        "print(\"Accuracy by tag: \", accuracy_by_tag)\n",
        "print(\"Average accuracy (macro-average): \", sum(accuracy_by_tag)/len(accuracy_by_tag))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
